defaults:
  - backend: pytorch # default backend
  - benchmark: inference # default benchmark
  - launcher: process # default launcher
  - experiment # inheriting from experiment config
  - _self_ # for hydra 1.1 compatibility
  - override hydra/job_logging: colorlog # colorful logging
  - override hydra/hydra_logging: colorlog # colorful logging

hydra:
  run:
    dir: experiments/${experiment_name}
  sweep:
    dir: experiments/${experiment_name}
  job:
    chdir: true
    env_set:
      CUDA_VISIBLE_DEVICES: 0
      CUDA_DEVICE_ORDER: PCI_BUS_ID
  sweeper:
    params:
      benchmark.input_shapes.batch_size: 1,2

experiment_name: fp16-batch_size(${benchmark.input_shapes.batch_size})-sequence_length(${benchmark.input_shapes.sequence_length})-new_tokens(${benchmark.new_tokens})

backend:
  torch_dtype: bfloat16
  device: cuda
  model: /home/chuan/models/qwen/Qwen1___5-7B-Chat
  task: text-generation
  library: transformers


benchmark:
  memory: true
  warmup_runs: 10

  new_tokens: 1000
  input_shapes:
    sequence_length: 512
